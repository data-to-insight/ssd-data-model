{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 166\u001b[0m\n\u001b[1;32m     13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvolvement_history_parsed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpers_involvement_history_json\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: ast\u001b[38;5;241m.\u001b[39mliteral_eval(x) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(x) \u001b[38;5;28;01melse\u001b[39;00m [])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# # CASE WORKER HISTORY\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# # Create a new DataFrame to store the parsed involvement history details, including WORKER_ID\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# involvement_history_expanded = pd.DataFrame([\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# WITHOUT CODE_DESC ADDED\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Create a new DataFrame to store the parsed involvement history details\u001b[39;00m\n\u001b[1;32m    164\u001b[0m involvement_history_expanded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\n\u001b[1;32m    165\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manon_person_id\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manon_person_id\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m--> 166\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvolvement_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43minvolvement\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mINVOLVEMENT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    167\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvolvement_type\u001b[39m\u001b[38;5;124m'\u001b[39m: involvement[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINVOLVEMENT_TYPE_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    168\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mto_datetime(involvement[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTART_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    169\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mto_datetime(involvement[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEND_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m])}\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows() \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvolvement_history_parsed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m involvement \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvolvement_history_parsed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    172\u001b[0m ])\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Apply the filter conditions\u001b[39;00m\n\u001b[1;32m    175\u001b[0m involvement_history_expanded_filtered \u001b[38;5;241m=\u001b[39m involvement_history_expanded[\n\u001b[1;32m    176\u001b[0m     (involvement_history_expanded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m    177\u001b[0m     (involvement_history_expanded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m involvement_history_expanded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m    178\u001b[0m     (involvement_history_expanded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1900-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    179\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Load your CSV data (update the file path if necessary)\n",
    "df = pd.read_csv('involvements_history_example_data.csv')\n",
    "\n",
    "# Parse the pers_involvement_history_json column, which contains JSON-like data\n",
    "df['involvement_history_parsed'] = df['pers_involvement_history_json'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # CASE WORKER HISTORY\n",
    "# # Create a new DataFrame to store the parsed involvement history details, including WORKER_ID\n",
    "# involvement_history_expanded = pd.DataFrame([\n",
    "#     {'anon_person_id': row['anon_person_id'], \n",
    "#      'involvement_id': involvement['INVOLVEMENT_ID'],\n",
    "#      'involvement_type': involvement['INVOLVEMENT_TYPE_CODE'],\n",
    "#      'worker_id': involvement['WORKER_ID'],\n",
    "#      'start_date': pd.to_datetime(involvement['START_DATE']),\n",
    "#      'end_date': pd.to_datetime(involvement['END_DATE'])}\n",
    "#     for _, row in df.iterrows() if row['involvement_history_parsed']\n",
    "#     for involvement in row['involvement_history_parsed']\n",
    "# ])\n",
    "\n",
    "# # Filter for only CW involvement type and other conditions\n",
    "# cw_filtered_data = involvement_history_expanded[\n",
    "#     (involvement_history_expanded['involvement_type'] == 'CW') &\n",
    "#     (involvement_history_expanded['start_date'] >= pd.Timestamp('2019-01-01')) &\n",
    "#     (involvement_history_expanded['end_date'] > involvement_history_expanded['start_date']) &\n",
    "#     (involvement_history_expanded['end_date'] != pd.Timestamp('1900-01-01'))\n",
    "# ]\n",
    "\n",
    "# # Calculate duration in days for each CW involvement\n",
    "# cw_filtered_data['duration_days'] = (cw_filtered_data['end_date'] - cw_filtered_data['start_date']).dt.days\n",
    "\n",
    "# # Anonymize the WORKER_IDs with sequential integers\n",
    "# unique_worker_ids = cw_filtered_data['worker_id'].unique()\n",
    "# anon_worker_map = {original_id: i+1 for i, original_id in enumerate(unique_worker_ids)}\n",
    "# cw_filtered_data['anon_worker_id'] = cw_filtered_data['worker_id'].map(anon_worker_map)\n",
    "\n",
    "# # Select the first 40 individuals with CW involvement for the plot\n",
    "# individuals_with_data = cw_filtered_data['anon_person_id'].unique()[:40]\n",
    "# subset_data_filtered = cw_filtered_data[cw_filtered_data['anon_person_id'].isin(individuals_with_data)]\n",
    "\n",
    "# # Generate unique colors for each anonymized worker ID\n",
    "# colormap = plt.cm.get_cmap('tab20', len(unique_worker_ids))\n",
    "# worker_colors = {anon_worker_map[worker_id]: colormap(i) for i, worker_id in enumerate(unique_worker_ids)}\n",
    "\n",
    "# # Plot the CW involvement history, using duration in days for the x-axis\n",
    "# plt.figure(figsize=(10, 8))\n",
    "\n",
    "# # Iterate through each person and plot each CW involvement per anon_worker_id with a unique color\n",
    "# for i, (anon_id, group) in enumerate(subset_data_filtered.groupby('anon_person_id')):\n",
    "#     for _, row in group.iterrows():\n",
    "#         plt.barh(i, row['duration_days'], left=0, color=worker_colors[row['anon_worker_id']], alpha=0.8)\n",
    "\n",
    "# # Create a legend with a unique entry for each anonymized WORKER_ID\n",
    "# handles = [plt.Rectangle((0,0),1,1, color=worker_colors[anon_worker_id]) for anon_worker_id in sorted(worker_colors.keys())]\n",
    "# plt.legend(handles, [f\"Worker {anon_worker_id}\" for anon_worker_id in sorted(worker_colors.keys())], title=\"WORKER_IDs\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# plt.title('Case Worker Involvements Timeline (from 01/01/2019)', fontsize=14)\n",
    "# plt.xlabel('Duration (Days)', fontsize=12)\n",
    "# plt.ylabel('Example Person', fontsize=12)\n",
    "# plt.yticks(ticks=range(len(individuals_with_data)), labels=range(1, len(individuals_with_data) + 1))\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ### CASEWORKER HISTORY AS SANKEY\n",
    "# # Create a new DataFrame to store the parsed involvement history details, including WORKER_ID\n",
    "# involvement_history_expanded = pd.DataFrame([\n",
    "#     {'anon_person_id': row['anon_person_id'], \n",
    "#      'involvement_id': involvement['INVOLVEMENT_ID'],\n",
    "#      'involvement_type': involvement['INVOLVEMENT_TYPE_CODE'],\n",
    "#      'worker_id': involvement['WORKER_ID'],\n",
    "#      'start_date': pd.to_datetime(involvement['START_DATE']),\n",
    "#      'end_date': pd.to_datetime(involvement['END_DATE'])}\n",
    "#     for _, row in df.iterrows() if row['involvement_history_parsed']\n",
    "#     for involvement in row['involvement_history_parsed']\n",
    "# ])\n",
    "\n",
    "# # Filter for only CW involvement type and other conditions\n",
    "# cw_filtered_data = involvement_history_expanded[\n",
    "#     (involvement_history_expanded['involvement_type'] == 'CW') &\n",
    "#     (involvement_history_expanded['start_date'] >= pd.Timestamp('2019-01-01')) &\n",
    "#     (involvement_history_expanded['end_date'] > involvement_history_expanded['start_date']) &\n",
    "#     (involvement_history_expanded['end_date'] != pd.Timestamp('1900-01-01'))\n",
    "# ].copy()  # .copy() avoids SettingWithCopyWarning\n",
    "\n",
    "# # Calculate duration in days for each CW involvement\n",
    "# cw_filtered_data.loc[:, 'duration_days'] = (cw_filtered_data['end_date'] - cw_filtered_data['start_date']).dt.days\n",
    "\n",
    "# # Anonymize the WORKER_IDs with sequential integers\n",
    "# unique_worker_ids = cw_filtered_data['worker_id'].unique()\n",
    "# anon_worker_map = {original_id: i+1 for i, original_id in enumerate(unique_worker_ids)}\n",
    "# cw_filtered_data.loc[:, 'anon_worker_id'] = cw_filtered_data['worker_id'].map(anon_worker_map)\n",
    "\n",
    "# # Select the first 40 individuals with CW involvement for the plot\n",
    "# individuals_with_data = cw_filtered_data['anon_person_id'].unique()[:40]\n",
    "# subset_data_filtered = cw_filtered_data[cw_filtered_data['anon_person_id'].isin(individuals_with_data)]\n",
    "\n",
    "# # Prepare labels for the nodes in the Sankey plot\n",
    "# person_labels = [f\"Person {i+1}\" for i in range(len(individuals_with_data))]\n",
    "# worker_labels = [f\"Worker {anon_worker_map[worker_id]}\" for worker_id in unique_worker_ids]\n",
    "# labels = person_labels + worker_labels\n",
    "\n",
    "# # Create mapping of person IDs and anonymized worker IDs to positions in the labels list\n",
    "# person_id_map = {anon_person_id: i for i, anon_person_id in enumerate(individuals_with_data)}\n",
    "# worker_id_map = {anon_worker_map[worker_id]: i + len(individuals_with_data) for i, worker_id in enumerate(unique_worker_ids)}\n",
    "\n",
    "\n",
    "# # Prepare source, target, and value lists for the Sankey plot\n",
    "# sources = []\n",
    "# targets = []\n",
    "# values = []\n",
    "\n",
    "# for _, row in subset_data_filtered.iterrows():\n",
    "#     sources.append(person_id_map[row['anon_person_id']])\n",
    "#     targets.append(worker_id_map[row['anon_worker_id']])\n",
    "#     values.append(row['duration_days'])  # Use duration as the value (thickness of the flow)\n",
    "\n",
    "# # Create the Sankey chart\n",
    "# fig = go.Figure(go.Sankey(\n",
    "#     node=dict(\n",
    "#         pad=15,\n",
    "#         thickness=20,\n",
    "#         line=dict(color=\"black\", width=0.5),\n",
    "#         label=labels\n",
    "#     ),\n",
    "#     link=dict(\n",
    "#         source=sources,  # indices of sources (persons)\n",
    "#         target=targets,  # indices of targets (anonymized workers)\n",
    "#         value=values     # durations in days\n",
    "#     )\n",
    "# ))\n",
    "\n",
    "# # Customize the layout\n",
    "# fig.update_layout(title_text=\"CW Involvements Timeline by Anonymized WORKER_ID (Duration as Flow Thickness)\", font_size=10)\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# WITHOUT CODE_DESC ADDED\n",
    "# Create a new DataFrame to store the parsed involvement history details\n",
    "involvement_history_expanded = pd.DataFrame([\n",
    "    {'anon_person_id': row['anon_person_id'], \n",
    "     'involvement_id': involvement['INVOLVEMENT_ID'],\n",
    "     'involvement_type': involvement['INVOLVEMENT_TYPE_CODE'],\n",
    "     'start_date': pd.to_datetime(involvement['START_DATE']),\n",
    "     'end_date': pd.to_datetime(involvement['END_DATE'])}\n",
    "    for _, row in df.iterrows() if row['involvement_history_parsed']\n",
    "    for involvement in row['involvement_history_parsed']\n",
    "])\n",
    "\n",
    "# Apply the filter conditions\n",
    "involvement_history_expanded_filtered = involvement_history_expanded[\n",
    "    (involvement_history_expanded['start_date'] >= pd.Timestamp('2019-01-01')) &\n",
    "    (involvement_history_expanded['end_date'] > involvement_history_expanded['start_date']) &\n",
    "    (involvement_history_expanded['end_date'] != pd.Timestamp('1900-01-01'))\n",
    "]\n",
    "\n",
    "# Calculate duration in days for each involvement\n",
    "involvement_history_expanded_filtered['duration_days'] = (involvement_history_expanded_filtered['end_date'] - involvement_history_expanded_filtered['start_date']).dt.days\n",
    "\n",
    "# Get distinct involvement types and rank them by frequency of occurrence\n",
    "top_30_involvement_types = involvement_history_expanded_filtered['involvement_type'].value_counts().index[:40]\n",
    "\n",
    "# Filter the data to include only the selected top 30 involvement types\n",
    "subset_data_filtered = involvement_history_expanded_filtered[involvement_history_expanded_filtered['involvement_type'].isin(top_30_involvement_types)]\n",
    "\n",
    "# Select only individuals who have data for the top 30 involvement types, ensuring there are no empty traces\n",
    "individuals_with_data = subset_data_filtered['anon_person_id'].unique()[:40]\n",
    "subset_data_filtered = subset_data_filtered[subset_data_filtered['anon_person_id'].isin(individuals_with_data)]\n",
    "\n",
    "# Use a colormap for 30 unique involvement types\n",
    "colormap = plt.cm.get_cmap('tab20', 30)  # 'tab20' can handle up to 20, so we'll repeat the scheme for 30 types\n",
    "\n",
    "# Map involvement types to colors\n",
    "involvement_colors = {inv_type: colormap(i % 20) for i, inv_type in enumerate(top_30_involvement_types)}\n",
    "\n",
    "# Plot the involvement history, using duration in days for the x-axis\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, (anon_id, group) in enumerate(subset_data_filtered.groupby('anon_person_id')):\n",
    "    for _, row in group.iterrows():\n",
    "        plt.barh(i, row['duration_days'], left=0, color=involvement_colors[row['involvement_type']], alpha=0.8)\n",
    "\n",
    "# Add a legend for the top 30 involvement types\n",
    "handles = [plt.Rectangle((0,0),1,1, color=involvement_colors[inv_type]) for inv_type in top_30_involvement_types]\n",
    "plt.legend(handles, top_30_involvement_types, title=\"Involvement Types\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Involvements Timeline (from 01/01/2019)', fontsize=14)\n",
    "plt.xlabel('Duration (Days)', fontsize=12)\n",
    "plt.ylabel('Example Person', fontsize=12)\n",
    "plt.yticks(ticks=range(len(individuals_with_data)), labels=range(1, len(individuals_with_data) + 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## SANKEY DIAGRAM\n",
    "\n",
    "# # Create a new DataFrame to store the parsed involvement history details, including start and end dates\n",
    "# involvement_history_expanded = pd.DataFrame([\n",
    "#     {'anon_person_id': row['anon_person_id'], \n",
    "#      'involvement_type': involvement['INVOLVEMENT_TYPE_CODE'],\n",
    "#      'start_date': pd.to_datetime(involvement['START_DATE']),\n",
    "#      'end_date': pd.to_datetime(involvement['END_DATE'])}\n",
    "#     for _, row in df.iterrows() if row['involvement_history_parsed']\n",
    "#     for involvement in row['involvement_history_parsed']\n",
    "# ])\n",
    "\n",
    "# # Apply the filter for valid data (post-2019) and remove invalid end dates\n",
    "# involvement_history_expanded_filtered = involvement_history_expanded[\n",
    "#     (involvement_history_expanded['start_date'] >= pd.Timestamp('2019-01-01')) &\n",
    "#     (involvement_history_expanded['end_date'] > involvement_history_expanded['start_date']) &\n",
    "#     (involvement_history_expanded['end_date'] != pd.Timestamp('1900-01-01'))\n",
    "# ]\n",
    "\n",
    "# # Calculate the duration in days\n",
    "# involvement_history_expanded_filtered['duration_days'] = (involvement_history_expanded_filtered['end_date'] - involvement_history_expanded_filtered['start_date']).dt.days\n",
    "\n",
    "# # Filter by the top 30 involvement types based on frequency\n",
    "# top_30_involvement_types = involvement_history_expanded_filtered['involvement_type'].value_counts().index[:30]\n",
    "# subset_data_filtered = involvement_history_expanded_filtered[involvement_history_expanded_filtered['involvement_type'].isin(top_30_involvement_types)]\n",
    "\n",
    "# # Get unique person IDs and limit to the first 10 people (or another number you prefer)\n",
    "# unique_persons = subset_data_filtered['anon_person_id'].unique()[:3]\n",
    "# unique_involvement_types = top_30_involvement_types\n",
    "\n",
    "# # Create the node labels (person IDs and involvement types)\n",
    "# labels = [f'Person {i}' for i in range(1, len(unique_persons) + 1)] + list(unique_involvement_types)\n",
    "\n",
    "# # Create a mapping for person IDs and involvement types to their indices in the labels list\n",
    "# person_id_map = {person: i for i, person in enumerate(unique_persons)}\n",
    "# involvement_type_map = {inv_type: i + len(unique_persons) for i, inv_type in enumerate(unique_involvement_types)}\n",
    "\n",
    "# # Create source and target indices for the Sankey chart based on durations\n",
    "# sources = []\n",
    "# targets = []\n",
    "# values = []\n",
    "\n",
    "# # Iterate over the data to create the links between persons and involvement types based on duration\n",
    "# for _, row in subset_data_filtered.iterrows():\n",
    "#     if row['anon_person_id'] in person_id_map:  # Only include persons within the top 10\n",
    "#         sources.append(person_id_map[row['anon_person_id']])\n",
    "#         targets.append(involvement_type_map[row['involvement_type']])\n",
    "#         values.append(row['duration_days'])  # Use duration in days as the value\n",
    "\n",
    "# # Create the Sankey chart\n",
    "# fig = go.Figure(go.Sankey(\n",
    "#     node=dict(\n",
    "#         pad=15,\n",
    "#         thickness=20,\n",
    "#         line=dict(color=\"black\", width=0.5),\n",
    "#         label=labels\n",
    "#     ),\n",
    "#     link=dict(\n",
    "#         source=sources,  # indices of sources (persons)\n",
    "#         target=targets,  # indices of targets (involvement types)\n",
    "#         value=values     # durations in days\n",
    "#     )\n",
    "# ))\n",
    "\n",
    "# # Customize the layout\n",
    "# fig.update_layout(title_text=\" Sankey: Involvement Types per Person/Duration\", font_size=10)\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
